Downloading (…)lve/main/config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|██████████| 1.60k/1.60k [00:00<00:00, 4.64MB/s]
Downloading model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]Downloading model.safetensors:   3%|▎         | 10.5M/378M [00:00<00:11, 33.0MB/s]Downloading model.safetensors:   6%|▌         | 21.0M/378M [00:00<00:07, 46.2MB/s]Downloading model.safetensors:   8%|▊         | 31.5M/378M [00:00<00:06, 54.0MB/s]Downloading model.safetensors:  11%|█         | 41.9M/378M [00:00<00:05, 60.6MB/s]Downloading model.safetensors:  14%|█▍        | 52.4M/378M [00:00<00:05, 65.0MB/s]Downloading model.safetensors:  17%|█▋        | 62.9M/378M [00:01<00:04, 67.2MB/s]Downloading model.safetensors:  19%|█▉        | 73.4M/378M [00:01<00:04, 68.0MB/s]Downloading model.safetensors:  22%|██▏       | 83.9M/378M [00:01<00:04, 68.1MB/s]Downloading model.safetensors:  25%|██▍       | 94.4M/378M [00:01<00:04, 69.5MB/s]Downloading model.safetensors:  28%|██▊       | 105M/378M [00:01<00:03, 71.0MB/s] Downloading model.safetensors:  31%|███       | 115M/378M [00:01<00:03, 71.2MB/s]Downloading model.safetensors:  33%|███▎      | 126M/378M [00:01<00:03, 72.3MB/s]Downloading model.safetensors:  36%|███▌      | 136M/378M [00:02<00:03, 73.4MB/s]Downloading model.safetensors:  39%|███▉      | 147M/378M [00:02<00:03, 73.7MB/s]Downloading model.safetensors:  42%|████▏     | 157M/378M [00:02<00:02, 73.5MB/s]Downloading model.safetensors:  44%|████▍     | 168M/378M [00:02<00:02, 73.7MB/s]Downloading model.safetensors:  47%|████▋     | 178M/378M [00:02<00:02, 74.4MB/s]Downloading model.safetensors:  50%|████▉     | 189M/378M [00:02<00:02, 74.0MB/s]Downloading model.safetensors:  53%|█████▎    | 199M/378M [00:02<00:02, 73.9MB/s]Downloading model.safetensors:  56%|█████▌    | 210M/378M [00:03<00:02, 73.1MB/s]Downloading model.safetensors:  58%|█████▊    | 220M/378M [00:03<00:02, 73.3MB/s]Downloading model.safetensors:  61%|██████    | 231M/378M [00:03<00:01, 74.0MB/s]Downloading model.safetensors:  64%|██████▍   | 241M/378M [00:03<00:01, 74.5MB/s]Downloading model.safetensors:  67%|██████▋   | 252M/378M [00:03<00:01, 75.2MB/s]Downloading model.safetensors:  69%|██████▉   | 262M/378M [00:03<00:01, 75.5MB/s]Downloading model.safetensors:  72%|███████▏  | 273M/378M [00:03<00:01, 75.4MB/s]Downloading model.safetensors:  75%|███████▍  | 283M/378M [00:04<00:01, 74.9MB/s]Downloading model.safetensors:  78%|███████▊  | 294M/378M [00:04<00:01, 74.5MB/s]Downloading model.safetensors:  81%|████████  | 304M/378M [00:04<00:00, 74.9MB/s]Downloading model.safetensors:  83%|████████▎ | 315M/378M [00:04<00:00, 74.3MB/s]Downloading model.safetensors:  86%|████████▌ | 325M/378M [00:04<00:00, 73.3MB/s]Downloading model.safetensors:  89%|████████▉ | 336M/378M [00:04<00:00, 72.3MB/s]Downloading model.safetensors:  92%|█████████▏| 346M/378M [00:04<00:00, 72.8MB/s]Downloading model.safetensors:  94%|█████████▍| 357M/378M [00:05<00:00, 73.0MB/s]Downloading model.safetensors:  97%|█████████▋| 367M/378M [00:05<00:00, 73.1MB/s]Downloading model.safetensors: 100%|█████████▉| 377M/378M [00:05<00:00, 73.6MB/s]Downloading model.safetensors: 100%|██████████| 378M/378M [00:05<00:00, 70.5MB/s]
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Downloading (…)rocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]Downloading (…)rocessor_config.json: 100%|██████████| 159/159 [00:00<00:00, 472kB/s]
Downloading (…)okenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|██████████| 163/163 [00:00<00:00, 494kB/s]
Downloading (…)olve/main/vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]Downloading (…)olve/main/vocab.json: 100%|██████████| 291/291 [00:00<00:00, 908kB/s]
Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|██████████| 85.0/85.0 [00:00<00:00, 282kB/s]
/users/mmlamah/.conda/envs/kiwano/lib/python3.10/site-packages/torchaudio/backend/sox_io_backend.py:416: UserWarning: File-like object support in sox_io backend is deprecated, and will be removed in v2.1. See https://github.com/pytorch/audio/issues/2950 for the detail.Please migrate to the new dispatcher, or use soundfile backend.
  warnings.warn(_deprecation_message)
/users/mmlamah/.conda/envs/kiwano/lib/python3.10/site-packages/torchaudio/backend/sox_io_backend.py:235: UserWarning: File-like object support in sox_io backend is deprecated, and will be removed in v2.1. See https://github.com/pytorch/audio/issues/2950 for the detail.Please migrate to the new dispatcher, or use soundfile backend.
  warnings.warn(_deprecation_message)
/users/mmlamah/.conda/envs/kiwano/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/users/mmlamah/.conda/envs/kiwano/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/users/mmlamah/.conda/envs/kiwano/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
10-24 14:35:20 [ 2] Lr: 0.000970, Training: 100.00%,  Loss: nan, ACC: 59.38% 